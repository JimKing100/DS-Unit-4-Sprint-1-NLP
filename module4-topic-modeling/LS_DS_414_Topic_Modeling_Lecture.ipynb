{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lambda School Data Science\n",
    "\n",
    "*Unit 4, Sprint 1, Module 4*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling (Prepare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Dirchilet Allocation (LDA) Models (Prepare)\n",
    "<a id=\"#p1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "LDA is a \"generative probabilistic model\". \n",
    "\n",
    "Let's play with a modoel available [here](https://lettier.com/projects/lda-topic-modeling/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow Along"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating LDA Models with Gensim (Learn)\n",
    "<a id=\"#p1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Overview\n",
    "### A Litterary Introduction: *Jane Austen V. Charlotte Bronte*\n",
    "Despite being born nearly forty years apart, modern fans often pit Jane Austen & Charlotte Bronte against one another in a battle for litterary  supremacy. The battle centers around the topics of education for women, courting, and marriage. The authors' similiar backgrounds naturally draw comparisons, but the modern fascination is probably due to novelility of British women publishing novels during the early 19th century. \n",
    "\n",
    "Can we help close a litterary battle for supremacy and simply acknowledge that the authors addressed different topics and deserve to be acknowledged as excellent authors each in their own right?\n",
    "\n",
    "We're going to apply Latent Dirichlet Allocation a machine learning alogrithm for topic modeling to each of the author's novels to compare the distribution of topics in their novels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.16.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.version.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gensim\n",
    "import os\n",
    "import re\n",
    "\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim import corpora\n",
    "\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Novel Data\n",
    "I grabbed the novel data pre-split into a bunch of smaller chuncks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data/austen-brontÃ«-split'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Plain Python - ''.split command\n",
    "# 2) Spacy - just the lemmas from the document\n",
    "# 3) Gensim - simple_preprocess\n",
    "\n",
    "def tokenize(text):\n",
    "    \n",
    "    return [token for token in simple_preprocess(text) if token in STOPWORDS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def gather_data(path_to_data): \n",
    "    data = []\n",
    "    for f in os.listdir(path):\n",
    "        if os.path.isdir(f) == False:\n",
    "            if f[-3:] == 'txt':\n",
    "                with open(os.path.join(path,f)) as t:\n",
    "                    text = t.read().strip('\\n')\n",
    "                    data.append(tokenize(str(text)))\n",
    "            \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = gather_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['she', 'found', 'that', 'he', 'was', 'only', 'his', 'an', 'of', 'the']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[0][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is a sample string with a  newline character'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"this is a sample string with a \\n newline character\".replace('\\n', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Follow Along"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Preprocessing\n",
    "**Challenge**: update the function `tokenize` with any technique you have learned so far this week. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [t[:-4] for t in os.listdir(path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "813"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Austen_Emma0026',\n",
       " 'Austen_Emma0032',\n",
       " 'CBronte_Villette0086',\n",
       " 'CBronte_Jane0099',\n",
       " 'CBronte_Villette0092']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = set(STOPWORDS).union(set(['said', 'mr', 'mrs']))\n",
    "\n",
    "def tokenize(text):\n",
    "    return [token for token in simple_preprocess(text) if token not in STOPWORDS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', 'world', 'test', 'tokenization', 'method']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(\"Hello World! This a test of the tokenization method\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(index=titles, data={'tokens':tokens})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Austen_Emma0026</th>\n",
       "      <td>[she, found, that, he, was, only, his, an, of,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Austen_Emma0032</th>\n",
       "      <td>[so, very, much, that, if, it, were, to, any, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CBronte_Villette0086</th>\n",
       "      <td>[the, there, the, on, the, but, where, was, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CBronte_Jane0099</th>\n",
       "      <td>[by, and, one, of, his, and, she, could, not, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CBronte_Villette0092</th>\n",
       "      <td>[on, the, the, first, the, of, not, what, as, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 tokens\n",
       "Austen_Emma0026       [she, found, that, he, was, only, his, an, of,...\n",
       "Austen_Emma0032       [so, very, much, that, if, it, were, to, any, ...\n",
       "CBronte_Villette0086  [the, there, the, on, the, but, where, was, th...\n",
       "CBronte_Jane0099      [by, and, one, of, his, and, she, could, not, ...\n",
       "CBronte_Villette0092  [on, the, the, first, the, of, not, what, as, ..."
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['author'] = df.reset_index()['index'].apply(lambda x: x.split('_')[0]).tolist()\n",
    "df['book'] = df.reset_index()['index'].apply(lambda x: x.split('_')[1][:-4]).tolist()\n",
    "df['section'] = df.reset_index()['index'].apply(lambda x: x[-4:]).tolist()\n",
    "df['section'] = df['section'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['author'] = df['author'].map({'Austen':1, 'CBronte':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    441\n",
       "1    372\n",
       "Name: author, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.author.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming Documents\n",
    "Here we use a new pythonic thingy: the `yield` statement in our fucntion. This allows us to iterate over a bunch of documents without actually reading them into memory. You can see how we use this fucntion later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_stream(path):\n",
    "    for f in os.listdir(path):\n",
    "        if os.path.isdir(f) == False:\n",
    "            if f[-3:] == 'txt':\n",
    "                with open(os.path.join(path,f)) as t:\n",
    "                    text = t.read().strip('\\n')\n",
    "                    tokens = tokenize(str(text))\n",
    "                yield tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming_data = doc_stream(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# gather_data => returns a list\n",
    "# doc_stream => returns a generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feels',\n",
       " 'like',\n",
       " 'snow',\n",
       " 'place',\n",
       " 'party',\n",
       " 'try',\n",
       " 'day',\n",
       " 'dissuade',\n",
       " 'father',\n",
       " 'venturing',\n",
       " 'mind',\n",
       " 'feel',\n",
       " 'cold',\n",
       " 'like',\n",
       " 'interfere',\n",
       " 'know',\n",
       " 'great',\n",
       " 'disappointment',\n",
       " 'weston',\n",
       " 'word',\n",
       " 'elton',\n",
       " 'case',\n",
       " 'certainly',\n",
       " 'excuse',\n",
       " 'appear',\n",
       " 'little',\n",
       " 'hoarse',\n",
       " 'consider',\n",
       " 'demand',\n",
       " 'voice',\n",
       " 'fatigues',\n",
       " 'morrow',\n",
       " 'bring',\n",
       " 'think',\n",
       " 'common',\n",
       " 'prudence',\n",
       " 'stay',\n",
       " 'home',\n",
       " 'care',\n",
       " 'night',\n",
       " 'elton',\n",
       " 'looked',\n",
       " 'know',\n",
       " 'answer',\n",
       " 'exactly',\n",
       " 'case',\n",
       " 'gratified',\n",
       " 'kind',\n",
       " 'care',\n",
       " 'fair',\n",
       " 'lady',\n",
       " 'liking',\n",
       " 'resist',\n",
       " 'advice',\n",
       " 'inclination',\n",
       " 'visit',\n",
       " 'emma',\n",
       " 'eager',\n",
       " 'busy',\n",
       " 'previous',\n",
       " 'conceptions',\n",
       " 'views',\n",
       " 'hear',\n",
       " 'impartially',\n",
       " 'clear',\n",
       " 'vision',\n",
       " 'satisfied',\n",
       " 'muttering',\n",
       " 'acknowledgment',\n",
       " 'cold',\n",
       " 'certainly',\n",
       " 'cold',\n",
       " 'walked',\n",
       " 'rejoicing',\n",
       " 'having',\n",
       " 'extricated',\n",
       " 'randalls',\n",
       " 'secured',\n",
       " 'power',\n",
       " 'sending',\n",
       " 'inquire',\n",
       " 'harriet',\n",
       " 'hour',\n",
       " 'evening',\n",
       " 'right',\n",
       " 'apologies',\n",
       " 'weston',\n",
       " 'hardly',\n",
       " 'spoken',\n",
       " 'brother',\n",
       " 'civilly',\n",
       " 'offering',\n",
       " 'seat',\n",
       " 'carriage',\n",
       " 'weather',\n",
       " 'elton',\n",
       " 'objection',\n",
       " 'elton',\n",
       " 'actually',\n",
       " 'accepting',\n",
       " 'offer',\n",
       " 'prompt',\n",
       " 'satisfaction',\n",
       " 'thing',\n",
       " 'elton',\n",
       " 'broad',\n",
       " 'handsome',\n",
       " 'face',\n",
       " 'expressed',\n",
       " 'pleasure',\n",
       " 'moment',\n",
       " 'smile',\n",
       " 'stronger',\n",
       " 'eyes',\n",
       " 'exulting',\n",
       " 'looked',\n",
       " 'strange',\n",
       " 'got',\n",
       " 'chuse',\n",
       " 'company',\n",
       " 'leave',\n",
       " 'harriet',\n",
       " 'ill',\n",
       " 'strange',\n",
       " 'believe',\n",
       " 'men',\n",
       " 'especially',\n",
       " 'single',\n",
       " 'men',\n",
       " 'inclination',\n",
       " 'passion',\n",
       " 'dining',\n",
       " 'dinner',\n",
       " 'engagement',\n",
       " 'high',\n",
       " 'class',\n",
       " 'pleasures',\n",
       " 'employments',\n",
       " 'dignities',\n",
       " 'duties',\n",
       " 'thing',\n",
       " 'gives',\n",
       " 'way',\n",
       " 'case',\n",
       " 'elton',\n",
       " 'valuable',\n",
       " 'amiable',\n",
       " 'pleasing',\n",
       " 'young',\n",
       " 'man',\n",
       " 'undoubtedly',\n",
       " 'love',\n",
       " 'harriet',\n",
       " 'refuse',\n",
       " 'invitation',\n",
       " 'dine',\n",
       " 'asked',\n",
       " 'strange',\n",
       " 'thing',\n",
       " 'love',\n",
       " 'ready',\n",
       " 'wit',\n",
       " 'harriet',\n",
       " 'dine',\n",
       " 'soon',\n",
       " 'elton',\n",
       " 'quitted',\n",
       " 'justice',\n",
       " 'feeling',\n",
       " 'great',\n",
       " 'deal',\n",
       " 'sentiment',\n",
       " 'manner',\n",
       " 'naming',\n",
       " 'harriet',\n",
       " 'parting',\n",
       " 'tone',\n",
       " 'voice',\n",
       " 'assuring',\n",
       " 'goddard',\n",
       " 'news',\n",
       " 'fair',\n",
       " 'friend',\n",
       " 'thing',\n",
       " 'prepared',\n",
       " 'happiness',\n",
       " 'meeting',\n",
       " 'hoped',\n",
       " 'able',\n",
       " 'better',\n",
       " 'report',\n",
       " 'sighed',\n",
       " 'smiled',\n",
       " 'way',\n",
       " 'left',\n",
       " 'balance',\n",
       " 'approbation',\n",
       " 'favour',\n",
       " 'minutes',\n",
       " 'entire',\n",
       " 'silence',\n",
       " 'john',\n",
       " 'knightley',\n",
       " 'began',\n",
       " 'life',\n",
       " 'saw',\n",
       " 'man',\n",
       " 'intent',\n",
       " 'agreeable',\n",
       " 'elton',\n",
       " 'downright',\n",
       " 'labour',\n",
       " 'ladies',\n",
       " 'concerned',\n",
       " 'men',\n",
       " 'rational',\n",
       " 'unaffected',\n",
       " 'ladies',\n",
       " 'feature',\n",
       " 'works',\n",
       " 'elton',\n",
       " 'manners',\n",
       " 'perfect',\n",
       " 'replied',\n",
       " 'emma',\n",
       " 'wish',\n",
       " 'ought',\n",
       " 'overlook',\n",
       " 'overlook',\n",
       " 'great',\n",
       " 'deal',\n",
       " 'man',\n",
       " 'best',\n",
       " 'moderate',\n",
       " 'powers',\n",
       " 'advantage',\n",
       " 'negligent',\n",
       " 'superiority',\n",
       " 'perfect',\n",
       " 'good',\n",
       " 'temper',\n",
       " 'good',\n",
       " 'elton',\n",
       " 'value',\n",
       " 'yes',\n",
       " 'john',\n",
       " 'knightley',\n",
       " 'presently',\n",
       " 'slyness',\n",
       " 'great',\n",
       " 'deal',\n",
       " 'good',\n",
       " 'replied',\n",
       " 'smile',\n",
       " 'astonishment',\n",
       " 'imagining',\n",
       " 'elton',\n",
       " 'object',\n",
       " 'imagination',\n",
       " 'crossed',\n",
       " 'emma',\n",
       " 'occurred',\n",
       " 'consideration',\n",
       " 'elton',\n",
       " 'love',\n",
       " 'idea',\n",
       " 'consider',\n",
       " 'regulate',\n",
       " 'behaviour',\n",
       " 'accordingly',\n",
       " 'think',\n",
       " 'manners',\n",
       " 'encouraging',\n",
       " 'speak',\n",
       " 'friend',\n",
       " 'emma',\n",
       " 'better',\n",
       " 'look',\n",
       " 'ascertain',\n",
       " 'mean',\n",
       " 'thank',\n",
       " 'assure',\n",
       " 'mistaken',\n",
       " 'elton',\n",
       " 'good',\n",
       " 'friends',\n",
       " 'walked',\n",
       " 'amusing',\n",
       " 'consideration',\n",
       " 'blunders',\n",
       " 'arise',\n",
       " 'partial',\n",
       " 'knowledge',\n",
       " 'circumstances',\n",
       " 'mistakes',\n",
       " 'people',\n",
       " 'high',\n",
       " 'pretensions',\n",
       " 'judgment',\n",
       " 'falling',\n",
       " 'pleased',\n",
       " 'brother',\n",
       " 'imagining',\n",
       " 'blind',\n",
       " 'ignorant',\n",
       " 'want',\n",
       " 'counsel',\n",
       " 'woodhouse',\n",
       " 'completely',\n",
       " 'mind',\n",
       " 'visit',\n",
       " 'spite',\n",
       " 'increasing',\n",
       " 'coldness',\n",
       " 'idea',\n",
       " 'shrinking',\n",
       " 'set',\n",
       " 'forward',\n",
       " 'punctually',\n",
       " 'eldest',\n",
       " 'daughter',\n",
       " 'carriage',\n",
       " 'apparent',\n",
       " 'consciousness',\n",
       " 'weather',\n",
       " 'wonder',\n",
       " 'going',\n",
       " 'pleasure',\n",
       " 'afford',\n",
       " 'randalls',\n",
       " 'cold',\n",
       " 'wrapt',\n",
       " 'feel',\n",
       " 'cold',\n",
       " 'severe',\n",
       " 'time',\n",
       " 'second',\n",
       " 'carriage',\n",
       " 'motion',\n",
       " 'flakes',\n",
       " 'snow',\n",
       " 'finding',\n",
       " 'way',\n",
       " 'sky',\n",
       " 'appearance',\n",
       " 'overcharged',\n",
       " 'want',\n",
       " 'milder',\n",
       " 'air',\n",
       " 'produce',\n",
       " 'white',\n",
       " 'world',\n",
       " 'short',\n",
       " 'time',\n",
       " 'emma',\n",
       " 'soon',\n",
       " 'saw',\n",
       " 'companion',\n",
       " 'happiest',\n",
       " 'humour',\n",
       " 'preparing',\n",
       " 'going',\n",
       " 'abroad',\n",
       " 'weather',\n",
       " 'sacrifice',\n",
       " 'children',\n",
       " 'dinner',\n",
       " 'evils',\n",
       " 'disagreeables',\n",
       " 'john',\n",
       " 'knightley',\n",
       " 'means',\n",
       " 'like',\n",
       " 'anticipated',\n",
       " 'visit',\n",
       " 'worth']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(streaming_data) # Returns one document at a time from the generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gensim LDA Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Dictionary Representation of all the words in our corpus\n",
    "id2word = corpora.Dictionary(doc_stream(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "869"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Id of the word in the dictionary\n",
    "id2word.token2id['england']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'england'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word[869]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(869, 3), (1254, 1), (2485, 1), (16851, 1)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bow - bag of words (id and count)\n",
    "id2word.doc2bow(tokenize(\"This is a sample message Darcy England England England\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Size of vocabulary\n",
    "import sys\n",
    "sys.getsizeof(id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22096"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Length of vocabulary across all documents\n",
    "len(id2word.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's remove extreme values from the dataset\n",
    "id2word.filter_extremes(no_below=5, no_above=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8103"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id2word.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a bag of words(bow) representation of our corpus\n",
    "# Note: we haven't actually read any text into memory here\n",
    "# Although abstracted away - toeknization IS happening in the doc_stream f(x)\n",
    "corpus = [id2word.doc2bow(text) for text in doc_stream(path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1),\n",
       " (1, 1),\n",
       " (2, 1),\n",
       " (3, 2),\n",
       " (4, 1),\n",
       " (5, 1),\n",
       " (6, 1),\n",
       " (7, 2),\n",
       " (8, 1),\n",
       " (9, 1)]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA model\n",
    "lda = LdaMulticore(corpus=corpus,    # data\n",
    "                   id2word=id2word,  # dictionary\n",
    "                   random_state=723812, # different results \n",
    "                   num_topics = 15, \n",
    "                   passes=10,        # default is 100\n",
    "                   workers=8\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.006*\"apples\" + 0.006*\"rochester\" + 0.006*\"heart\" + 0.005*\"master\" + 0.004*\"kept\" + 0.004*\"face\" + 0.004*\"william\" + 0.004*\"miss\" + 0.004*\"love\" + 0.003*\"ingram\"'),\n",
       " (1,\n",
       "  '0.015*\"emma\" + 0.011*\"miss\" + 0.009*\"harriet\" + 0.008*\"weston\" + 0.007*\"thing\" + 0.007*\"think\" + 0.007*\"knightley\" + 0.007*\"elton\" + 0.006*\"good\" + 0.006*\"little\"'),\n",
       " (2,\n",
       "  '0.012*\"crimsworth\" + 0.012*\"hunsden\" + 0.007*\"house\" + 0.005*\"old\" + 0.005*\"like\" + 0.005*\"edward\" + 0.004*\"good\" + 0.004*\"man\" + 0.004*\"thought\" + 0.003*\"face\"'),\n",
       " (3,\n",
       "  '0.007*\"dr\" + 0.006*\"paul\" + 0.006*\"thought\" + 0.006*\"john\" + 0.004*\"know\" + 0.004*\"day\" + 0.004*\"hand\" + 0.004*\"madame\" + 0.004*\"good\" + 0.004*\"monsieur\"'),\n",
       " (4,\n",
       "  '0.014*\"little\" + 0.013*\"graham\" + 0.013*\"bretton\" + 0.008*\"papa\" + 0.008*\"like\" + 0.007*\"lucy\" + 0.006*\"dr\" + 0.006*\"think\" + 0.005*\"miss\" + 0.005*\"polly\"'),\n",
       " (5,\n",
       "  '0.006*\"like\" + 0.005*\"little\" + 0.004*\"know\" + 0.004*\"day\" + 0.004*\"thought\" + 0.004*\"good\" + 0.004*\"time\" + 0.004*\"night\" + 0.004*\"long\" + 0.003*\"madame\"'),\n",
       " (6,\n",
       "  '0.006*\"long\" + 0.005*\"like\" + 0.005*\"room\" + 0.005*\"door\" + 0.005*\"time\" + 0.004*\"night\" + 0.004*\"miss\" + 0.004*\"looked\" + 0.004*\"little\" + 0.004*\"garden\"'),\n",
       " (7,\n",
       "  '0.006*\"madame\" + 0.005*\"time\" + 0.004*\"good\" + 0.003*\"like\" + 0.003*\"thought\" + 0.003*\"little\" + 0.003*\"old\" + 0.003*\"man\" + 0.003*\"beck\" + 0.003*\"door\"'),\n",
       " (8,\n",
       "  '0.008*\"elizabeth\" + 0.007*\"know\" + 0.006*\"miss\" + 0.006*\"time\" + 0.005*\"think\" + 0.005*\"soon\" + 0.005*\"elinor\" + 0.005*\"good\" + 0.005*\"lady\" + 0.005*\"mother\"'),\n",
       " (9,\n",
       "  '0.018*\"marianne\" + 0.014*\"elinor\" + 0.009*\"sister\" + 0.008*\"willoughby\" + 0.007*\"darcy\" + 0.006*\"miss\" + 0.006*\"bingley\" + 0.006*\"elizabeth\" + 0.005*\"mother\" + 0.005*\"time\"'),\n",
       " (10,\n",
       "  '0.012*\"monsieur\" + 0.007*\"little\" + 0.005*\"frances\" + 0.005*\"mdlle\" + 0.005*\"english\" + 0.004*\"thought\" + 0.004*\"like\" + 0.004*\"good\" + 0.003*\"think\" + 0.003*\"yes\"'),\n",
       " (11,\n",
       "  '0.008*\"little\" + 0.004*\"time\" + 0.004*\"looked\" + 0.004*\"thought\" + 0.004*\"monsieur\" + 0.004*\"eyes\" + 0.003*\"est\" + 0.003*\"day\" + 0.003*\"face\" + 0.003*\"vous\"'),\n",
       " (12,\n",
       "  '0.014*\"rochester\" + 0.011*\"sir\" + 0.009*\"jane\" + 0.007*\"miss\" + 0.007*\"room\" + 0.006*\"bessie\" + 0.006*\"adele\" + 0.005*\"like\" + 0.005*\"fairfax\" + 0.005*\"yes\"'),\n",
       " (13,\n",
       "  '0.005*\"like\" + 0.005*\"rochester\" + 0.004*\"face\" + 0.004*\"ingram\" + 0.004*\"write\" + 0.004*\"miss\" + 0.003*\"long\" + 0.003*\"ladies\" + 0.003*\"saw\" + 0.003*\"little\"'),\n",
       " (14,\n",
       "  '0.010*\"pelet\" + 0.006*\"little\" + 0.006*\"reuter\" + 0.005*\"thought\" + 0.005*\"day\" + 0.005*\"garden\" + 0.004*\"large\" + 0.004*\"mdlle\" + 0.004*\"time\" + 0.004*\"door\"')]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip out the words\n",
    "words = [re.findall(r'\"([^\"]*)\"',t[1]) for t in lda.print_topics()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [' '.join(t[0:5]) for t in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Topic 0 ------\n",
      "apples rochester heart master kept\n",
      "\n",
      "------ Topic 1 ------\n",
      "emma miss harriet weston thing\n",
      "\n",
      "------ Topic 2 ------\n",
      "crimsworth hunsden house old like\n",
      "\n",
      "------ Topic 3 ------\n",
      "dr paul thought john know\n",
      "\n",
      "------ Topic 4 ------\n",
      "little graham bretton papa like\n",
      "\n",
      "------ Topic 5 ------\n",
      "like little know day thought\n",
      "\n",
      "------ Topic 6 ------\n",
      "long like room door time\n",
      "\n",
      "------ Topic 7 ------\n",
      "madame time good like thought\n",
      "\n",
      "------ Topic 8 ------\n",
      "elizabeth know miss time think\n",
      "\n",
      "------ Topic 9 ------\n",
      "marianne elinor sister willoughby darcy\n",
      "\n",
      "------ Topic 10 ------\n",
      "monsieur little frances mdlle english\n",
      "\n",
      "------ Topic 11 ------\n",
      "little time looked thought monsieur\n",
      "\n",
      "------ Topic 12 ------\n",
      "rochester sir jane miss room\n",
      "\n",
      "------ Topic 13 ------\n",
      "like rochester face ingram write\n",
      "\n",
      "------ Topic 14 ------\n",
      "pelet little reuter thought day\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for id, t in enumerate(topics): \n",
    "    print(f\"------ Topic {id} ------\")\n",
    "    print(t, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge \n",
    "\n",
    "You will apply an LDA model to a customer review dataset to practice the fitting and estimation of LDA. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpret LDA Results (Learn)\n",
    "<a id=\"#p3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Follow Along"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Distance Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim\n",
    "\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This takes an enormous amount of time to run\n",
    "# pyLDAvis.gensim.prepare(lda, corpus, id2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Model / Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0.9351618), (8, 0.06256347)]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda[corpus[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "distro = [lda[d] for d in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0.9348644), (8, 0.06286082)]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distro[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fills in list with the empty values\n",
    "distro = [lda[d] for d in corpus]\n",
    "\n",
    "def update(doc):\n",
    "        d_dist = {k:0 for k in range(0,15)}\n",
    "        for t in doc:\n",
    "            d_dist[t[0]] = t[1]\n",
    "        return d_dist\n",
    "    \n",
    "new_distro = [update(d) for d in distro]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(new_distro, index=titles)\n",
    "df.columns = topics\n",
    "df['author'] = df.reset_index()['index'].apply(lambda x: x.split('_')[0]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>apples rochester heart master kept</th>\n",
       "      <th>emma miss harriet weston thing</th>\n",
       "      <th>crimsworth hunsden house old like</th>\n",
       "      <th>dr paul thought john know</th>\n",
       "      <th>little graham bretton papa like</th>\n",
       "      <th>like little know day thought</th>\n",
       "      <th>long like room door time</th>\n",
       "      <th>madame time good like thought</th>\n",
       "      <th>elizabeth know miss time think</th>\n",
       "      <th>marianne elinor sister willoughby darcy</th>\n",
       "      <th>monsieur little frances mdlle english</th>\n",
       "      <th>little time looked thought monsieur</th>\n",
       "      <th>rochester sir jane miss room</th>\n",
       "      <th>like rochester face ingram write</th>\n",
       "      <th>pelet little reuter thought day</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Austen_Emma0026</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.934563</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.063162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Austen_Emma0032</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997457</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CBronte_Villette0086</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.260679</td>\n",
       "      <td>0.737110</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CBronte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CBronte_Jane0099</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.997619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CBronte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CBronte_Villette0092</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047950</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.220559</td>\n",
       "      <td>0.729689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CBronte</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      apples rochester heart master kept  \\\n",
       "Austen_Emma0026                                      0.0   \n",
       "Austen_Emma0032                                      0.0   \n",
       "CBronte_Villette0086                                 0.0   \n",
       "CBronte_Jane0099                                     0.0   \n",
       "CBronte_Villette0092                                 0.0   \n",
       "\n",
       "                      emma miss harriet weston thing  \\\n",
       "Austen_Emma0026                             0.934563   \n",
       "Austen_Emma0032                             0.997457   \n",
       "CBronte_Villette0086                        0.000000   \n",
       "CBronte_Jane0099                            0.000000   \n",
       "CBronte_Villette0092                        0.047950   \n",
       "\n",
       "                      crimsworth hunsden house old like  \\\n",
       "Austen_Emma0026                                     0.0   \n",
       "Austen_Emma0032                                     0.0   \n",
       "CBronte_Villette0086                                0.0   \n",
       "CBronte_Jane0099                                    0.0   \n",
       "CBronte_Villette0092                                0.0   \n",
       "\n",
       "                      dr paul thought john know  \\\n",
       "Austen_Emma0026                             0.0   \n",
       "Austen_Emma0032                             0.0   \n",
       "CBronte_Villette0086                        0.0   \n",
       "CBronte_Jane0099                            0.0   \n",
       "CBronte_Villette0092                        0.0   \n",
       "\n",
       "                      little graham bretton papa like  \\\n",
       "Austen_Emma0026                              0.000000   \n",
       "Austen_Emma0032                              0.000000   \n",
       "CBronte_Villette0086                         0.260679   \n",
       "CBronte_Jane0099                             0.000000   \n",
       "CBronte_Villette0092                         0.220559   \n",
       "\n",
       "                      like little know day thought  long like room door time  \\\n",
       "Austen_Emma0026                           0.000000                  0.000000   \n",
       "Austen_Emma0032                           0.000000                  0.000000   \n",
       "CBronte_Villette0086                      0.737110                  0.000000   \n",
       "CBronte_Jane0099                          0.000000                  0.997619   \n",
       "CBronte_Villette0092                      0.729689                  0.000000   \n",
       "\n",
       "                      madame time good like thought  \\\n",
       "Austen_Emma0026                                 0.0   \n",
       "Austen_Emma0032                                 0.0   \n",
       "CBronte_Villette0086                            0.0   \n",
       "CBronte_Jane0099                                0.0   \n",
       "CBronte_Villette0092                            0.0   \n",
       "\n",
       "                      elizabeth know miss time think  \\\n",
       "Austen_Emma0026                             0.063162   \n",
       "Austen_Emma0032                             0.000000   \n",
       "CBronte_Villette0086                        0.000000   \n",
       "CBronte_Jane0099                            0.000000   \n",
       "CBronte_Villette0092                        0.000000   \n",
       "\n",
       "                      marianne elinor sister willoughby darcy  \\\n",
       "Austen_Emma0026                                           0.0   \n",
       "Austen_Emma0032                                           0.0   \n",
       "CBronte_Villette0086                                      0.0   \n",
       "CBronte_Jane0099                                          0.0   \n",
       "CBronte_Villette0092                                      0.0   \n",
       "\n",
       "                      monsieur little frances mdlle english  \\\n",
       "Austen_Emma0026                                         0.0   \n",
       "Austen_Emma0032                                         0.0   \n",
       "CBronte_Villette0086                                    0.0   \n",
       "CBronte_Jane0099                                        0.0   \n",
       "CBronte_Villette0092                                    0.0   \n",
       "\n",
       "                      little time looked thought monsieur  \\\n",
       "Austen_Emma0026                                       0.0   \n",
       "Austen_Emma0032                                       0.0   \n",
       "CBronte_Villette0086                                  0.0   \n",
       "CBronte_Jane0099                                      0.0   \n",
       "CBronte_Villette0092                                  0.0   \n",
       "\n",
       "                      rochester sir jane miss room  \\\n",
       "Austen_Emma0026                                0.0   \n",
       "Austen_Emma0032                                0.0   \n",
       "CBronte_Villette0086                           0.0   \n",
       "CBronte_Jane0099                               0.0   \n",
       "CBronte_Villette0092                           0.0   \n",
       "\n",
       "                      like rochester face ingram write  \\\n",
       "Austen_Emma0026                                    0.0   \n",
       "Austen_Emma0032                                    0.0   \n",
       "CBronte_Villette0086                               0.0   \n",
       "CBronte_Jane0099                                   0.0   \n",
       "CBronte_Villette0092                               0.0   \n",
       "\n",
       "                      pelet little reuter thought day   author  \n",
       "Austen_Emma0026                                   0.0   Austen  \n",
       "Austen_Emma0032                                   0.0   Austen  \n",
       "CBronte_Villette0086                              0.0  CBronte  \n",
       "CBronte_Jane0099                                  0.0  CBronte  \n",
       "CBronte_Villette0092                              0.0  CBronte  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>apples rochester heart master kept</th>\n",
       "      <th>emma miss harriet weston thing</th>\n",
       "      <th>crimsworth hunsden house old like</th>\n",
       "      <th>dr paul thought john know</th>\n",
       "      <th>little graham bretton papa like</th>\n",
       "      <th>like little know day thought</th>\n",
       "      <th>long like room door time</th>\n",
       "      <th>madame time good like thought</th>\n",
       "      <th>elizabeth know miss time think</th>\n",
       "      <th>marianne elinor sister willoughby darcy</th>\n",
       "      <th>monsieur little frances mdlle english</th>\n",
       "      <th>little time looked thought monsieur</th>\n",
       "      <th>rochester sir jane miss room</th>\n",
       "      <th>like rochester face ingram write</th>\n",
       "      <th>pelet little reuter thought day</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Austen</th>\n",
       "      <td>0.000757</td>\n",
       "      <td>0.380365</td>\n",
       "      <td>0.003865</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.004106</td>\n",
       "      <td>0.006985</td>\n",
       "      <td>0.000990</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.418397</td>\n",
       "      <td>0.174764</td>\n",
       "      <td>0.00173</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002738</td>\n",
       "      <td>0.002529</td>\n",
       "      <td>0.000063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CBronte</th>\n",
       "      <td>0.004425</td>\n",
       "      <td>0.010330</td>\n",
       "      <td>0.015358</td>\n",
       "      <td>0.016859</td>\n",
       "      <td>0.079202</td>\n",
       "      <td>0.540285</td>\n",
       "      <td>0.034786</td>\n",
       "      <td>0.021041</td>\n",
       "      <td>0.022976</td>\n",
       "      <td>0.001003</td>\n",
       "      <td>0.07863</td>\n",
       "      <td>0.022831</td>\n",
       "      <td>0.130277</td>\n",
       "      <td>0.006877</td>\n",
       "      <td>0.012492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         apples rochester heart master kept  emma miss harriet weston thing  \\\n",
       "author                                                                        \n",
       "Austen                             0.000757                        0.380365   \n",
       "CBronte                            0.004425                        0.010330   \n",
       "\n",
       "         crimsworth hunsden house old like  dr paul thought john know  \\\n",
       "author                                                                  \n",
       "Austen                            0.003865                   0.000041   \n",
       "CBronte                           0.015358                   0.016859   \n",
       "\n",
       "         little graham bretton papa like  like little know day thought  \\\n",
       "author                                                                   \n",
       "Austen                          0.004106                      0.006985   \n",
       "CBronte                         0.079202                      0.540285   \n",
       "\n",
       "         long like room door time  madame time good like thought  \\\n",
       "author                                                             \n",
       "Austen                   0.000990                       0.000000   \n",
       "CBronte                  0.034786                       0.021041   \n",
       "\n",
       "         elizabeth know miss time think  \\\n",
       "author                                    \n",
       "Austen                         0.418397   \n",
       "CBronte                        0.022976   \n",
       "\n",
       "         marianne elinor sister willoughby darcy  \\\n",
       "author                                             \n",
       "Austen                                  0.174764   \n",
       "CBronte                                 0.001003   \n",
       "\n",
       "         monsieur little frances mdlle english  \\\n",
       "author                                           \n",
       "Austen                                 0.00173   \n",
       "CBronte                                0.07863   \n",
       "\n",
       "         little time looked thought monsieur  rochester sir jane miss room  \\\n",
       "author                                                                       \n",
       "Austen                              0.000000                      0.002738   \n",
       "CBronte                             0.022831                      0.130277   \n",
       "\n",
       "         like rochester face ingram write  pelet little reuter thought day  \n",
       "author                                                                      \n",
       "Austen                           0.002529                         0.000063  \n",
       "CBronte                          0.006877                         0.012492  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('author').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "### *Can we see if one of the authors focus more on men than women?*\n",
    "\n",
    "*  Use Spacy for text prepocessing\n",
    "*  Extract the Named Entities from the documents using Spacy (command is fairly straight forward)\n",
    "*  Create unique list of names from the authors (you'll find that there are different types of named entities not all people)\n",
    "*  Label the names with genders (can you this by hand or you use the US census name lists)\n",
    "*  Customize your processing to replace the proper name with your gender from the previous step's lookup table\n",
    "*  Then follow the rest of the LDA flow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting the Number of Topics (Learn)\n",
    "<a id=\"#p4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow Along"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "def compute_coherence_values(dictionary, corpus, path, limit, start=2, step=3, passes=5):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    path : path to input texts\n",
    "    limit : Max num of topics\n",
    "    passes: the number of times the entire lda model & coherence values are calculated\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    \n",
    "    coherence_values = []\n",
    "    \n",
    "    tokens = list(doc_stream(path))\n",
    "    \n",
    "    for iter_ in range(passes):\n",
    "        for num_topics in range(start, limit, step):\n",
    "            stream = doc_stream(path)\n",
    "            model = LdaMulticore(corpus=corpus, num_topics=num_topics, id2word=dictionary, workers=4)\n",
    "            coherencemodel = CoherenceModel(model=model,dictionary=dictionary,corpus=corpus, coherence='u_mass')\n",
    "            coherence_values.append({'pass': iter_, \n",
    "                                     'num_topics': num_topics, \n",
    "                                     'coherence_score': coherencemodel.get_coherence()\n",
    "                                    })\n",
    "\n",
    "    return coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can take a long time to run.\n",
    "# coherence_values = compute_coherence_values(dictionary=id2word, \n",
    "#                                                        corpus=corpus, \n",
    "#                                                        path=path, \n",
    "#                                                        start=2, \n",
    "#                                                        limit=40, \n",
    "#                                                        step=6,\n",
    "#                                                        passes=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_coherence = pd.DataFrame.from_records(coherence_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coherence_score</th>\n",
       "      <th>num_topics</th>\n",
       "      <th>pass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.935416</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.939436</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.952264</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.912855</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.905050</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   coherence_score  num_topics  pass\n",
       "0        -0.935416           2     0\n",
       "1        -0.939436           8     0\n",
       "2        -0.952264          14     0\n",
       "3        -0.912855          20     0\n",
       "4        -0.905050          26     0"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_coherence.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "ax = sns.lineplot(x=\"num_topics\", y=\"coherence_score\", data=topic_coherence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Topics = 2  has Coherence Value of 0.2785\n",
      "Num Topics = 8  has Coherence Value of 0.3029\n",
      "Num Topics = 14  has Coherence Value of 0.2887\n",
      "Num Topics = 20  has Coherence Value of 0.2852\n",
      "Num Topics = 26  has Coherence Value of 0.2846\n",
      "Num Topics = 32  has Coherence Value of 0.2914\n",
      "Num Topics = 38  has Coherence Value of 0.2878\n"
     ]
    }
   ],
   "source": [
    "# Print the coherence scores\n",
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.02226036),\n",
       " (1, 0.022260414),\n",
       " (2, 0.022260347),\n",
       " (3, 0.022260347),\n",
       " (4, 0.022260392),\n",
       " (5, 0.0222604),\n",
       " (6, 0.022260347),\n",
       " (7, 0.35487327),\n",
       " (8, 0.022260398),\n",
       " (9, 0.022260517),\n",
       " (10, 0.022260416),\n",
       " (11, 0.022260422),\n",
       " (12, 0.3557417),\n",
       " (13, 0.022260347),\n",
       " (14, 0.022260347)]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda[id2word.doc2bow(tokenize(\"This is a sample document to score with a topic distribution.\"))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "### *Can we see if one of the authors focus more on men than women?*\n",
    "\n",
    "*  Use Spacy for text prepocessing\n",
    "*  Extract the Named Entities from the documents using Spacy (command is fairly straight forward)\n",
    "*  Create unique list of names from the authors (you'll find that there are different types of named entities not all people)\n",
    "*  Label the names with genders (can you this by hand or you use the US census name lists)\n",
    "*  Customize your processing to replace the proper name with your gender from the previous step's lookup table\n",
    "*  Then follow the rest of the LDA flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/JKMacBook/opt/anaconda3/envs/nlp-1/lib/python3.7/site-packages/thinc/neural/train.py:7: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from .optimizers import Adam, linear_decay\n",
      "/Users/JKMacBook/opt/anaconda3/envs/nlp-1/lib/python3.7/site-packages/thinc/check.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sequence, Sized, Iterable, Callable\n",
      "/Users/JKMacBook/opt/anaconda3/envs/nlp-1/lib/python3.7/site-packages/thinc/check.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sequence, Sized, Iterable, Callable\n",
      "/Users/JKMacBook/opt/anaconda3/envs/nlp-1/lib/python3.7/site-packages/thinc/check.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sequence, Sized, Iterable, Callable\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"Ned asked me a question about England today.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ned Ned PROPN\n",
      "asked ask VERB\n",
      "me -PRON- PRON\n",
      "a a DET\n",
      "question question NOUN\n",
      "about about ADP\n",
      "England England PROPN\n",
      "today today NOUN\n",
      ". . PUNCT\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(test)\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ned PERSON\n",
      "England GPE\n",
      "today DATE\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_stream(path):\n",
    "    for f in os.listdir(path):\n",
    "        with open(os.path.join(path,f)) as t:\n",
    "            text = t.read().strip('\\n')\n",
    "            yield text\n",
    "\n",
    "def get_people(docstream):\n",
    "    \n",
    "    ppl = []\n",
    "    \n",
    "    for d in docstream:\n",
    "        \n",
    "        doc = nlp(d)\n",
    "        \n",
    "        for ent in doc.ents:\n",
    "            \n",
    "            if ent.label_ == \"PERSON\":\n",
    "                ppl.append(ent.lemma_)\n",
    "                \n",
    "    return set(ppl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# people = get_people(doc_stream(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(next(doc_stream(path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yesterday'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.ents[0].lemma_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources\n",
    "\n",
    "### *References*\n",
    "* [Andrew Ng et al paper on LDA](https://ai.stanford.edu/~ang/papers/jair03-lda.pdf)\n",
    "* On [Coherence](https://pdfs.semanticscholar.org/1521/8d9c029cbb903ae7c729b2c644c24994c201.pdf)\n",
    "\n",
    "### *Resources*\n",
    "\n",
    "* [Gensim](https://radimrehurek.com/gensim/): Python package for topic modeling, nlp, word vectorization, and few other things. Well maintained and well documented.\n",
    "* [Topic Modeling with Gensim](http://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/#11createthedictionaryandcorpusneededfortopicmodeling): A kind of cookbook for LDA with gensim. Excellent overview, but the you need to be aware of missing import statements and assumed prior knowledge.\n",
    "* [Chinese Restuarant Process](https://en.wikipedia.org/wiki/Chinese_restaurant_process): That really obscure stats thing I mentioned... \n",
    "* [PyLDAvis](https://github.com/bmabey/pyLDAvis): Library for visualizing the topic model and performing some exploratory work. Works well. Has a direct parrell implementation in R as well. \n",
    "* [Rare Technologies](https://rare-technologies.com/): The people that made & maintain gensim and a few other libraries.\n",
    "* [Jane Austen v. Charlotte Bronte](https://www.literaryladiesguide.com/literary-musings/jane-austen-charlotte-bronte-different-alike/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-1 (Python3)",
   "language": "python",
   "name": "nlp-1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
